"""
copperfish.models

Data model for the Shipyard (Copperfish) project - open source software
that performs revision control on datasets and bioinformatic pipelines.
"""

from django.db import models;
from django.contrib.auth.models import User;
from django.contrib.contenttypes.models import ContentType;
from django.contrib.contenttypes import generic;
from django.db.models.signals import pre_save, post_save;
from django.dispatch import receiver;
from django.core.exceptions import ValidationError;
from django.core.validators import MinValueValidator;

import operator;		# Python math functions
import hashlib;			# To calculate MD5 hash
import re;			# Regular expressions
import string;			# Augments regular expressions
import os.path;                 # For checking file paths
import sys;

class Datatype(models.Model):
	"""
	Abstract definition of a semantically atomic type of data.
	Related to :model:`copperfish.CompoundDatatype`
	"""

	# Implicitly defined
	#   restricted_by (self/ManyToMany)
	#   compoundDatatypeMember_set (ForeignKey)

	name = models.CharField(
			"Datatype name",
			max_length=64,
			help_text="The name for this DataType");

	# auto_now_add: set to now on instantiation (editable=False)
	date_created = models.DateTimeField(
			'Date created',
			auto_now_add = True,
			help_text="Date Datatype was defined");

	description = models.TextField(
			"Datatype description",
			help_text="A description for this DataType");

	# Datatypes aren't always generated by python but are VALIDATED
	# with Python.
	# FIXME: do we need this or is this just unnecessary
	# repetition since we have a verification script that will do the
	# requisite checking?
	Python_type = models.CharField(
			'Python variable type',
			max_length=64,
			help_text="Python type, such as String, Int, Date");

	# FIXME: Check for circularly defined restrictions -- write a clean() method
	restricts = models.ManyToManyField(
			'self',
			symmetrical=False,
			related_name="restricted_by",
			null=True,
			blank=True,
			help_text="Captures hierarchical is-a classifications among Datatypes");

	verification_script = models.FileField(
			"Verification script",
			upload_to='VerificationScripts',
			help_text="Used to validate correctness of fields labelled as being this DataType");

	
	def is_restricted_by(self, possible_restrictor_datatype):
		"""
		Determine if self is ever directly or indirectly
		restricted by a given datatype.
		"""

		# We assume self is not restricted by possible_restrictor_datatype
		is_restricted = False
		restrictions = possible_restrictor_datatype.restricts.all()

		for restrictedDataType in restrictions:

			# Case 1: If restrictions restrict self, return true
			if restrictedDataType == self:
				is_restricted = True

			# Case 2: Check if any restricted Datatypes themselves restrict self
			else:
				theValue = self.is_restricted_by(restrictedDataType)

				# If any restricted Datatypes themselves restrict self, propagate
				# this information to the parent Datatype as restricting self
				if theValue == True:
					is_restricted = True

		# Return False if Case 1 is never encountered
		return is_restricted

	def clean(self):
		if (self.is_restricted_by(self)):
			raise ValidationError("Circular Datatype restriction detected");

	def __unicode__(self):
		"""Describe Datatype by name"""
		return self.name;

class CompoundDatatypeMember(models.Model):
	"""
	A data type member of a particular CompoundDatatype.
	Related to :model:`copperfish.Dataset`
	Related to :model:`copperfish.CompoundDatatype`
	"""

	compounddatatype = models.ForeignKey(
			"CompoundDatatype",
			related_name="members",
			help_text="Links this DataType member to a particular CompoundDataType");

	datatype = models.ForeignKey(
			Datatype,
			help_text="Specifies which DataType this member is");

	column_name = models.CharField(
			"Column name",
			max_length=128,
			help_text="Gives datatype a 'collumn name' as an alternative to collumn index");

	# MinValueValidator(1) constrains column_idx to be >= 1
	column_idx = models.PositiveIntegerField(
			validators=[MinValueValidator(1)],
			help_text="The column number of this DataType");

	# Define database indexing rules to ensure tuple uniqueness
	# A compoundDataType cannot have 2 member definitions with the same column name or column number
	class Meta:
		unique_together = 	(("compounddatatype", "column_name"),
							("compounddatatype", "column_idx"));

	def __unicode__(self):
		"""Describe a CompoundDatatypeMember with it's column number, datatype name, and column name"""

		returnString = u"{}: <{}> [{}]".format( self.column_idx,
												unicode(self.datatype),
												self.column_name);

		return returnString

class CompoundDatatype(models.Model):
	"""
	A definition of a structured collection of datatypes,
	the resultant data structure serving as inputs or outputs
	for a Transformation.

	Related to :model:`copperfish.CompoundDatatypeMember`
	Related to :model:`copperfish.Dataset`
	"""

	# Implicitly defined:
	#   members (CompoundDatatypeMember/ForeignKey)
	#   Conforming_datasets (Dataset/ForeignKey)

	def __unicode__(self):
		""" Represent CompoundDatatype with a list of it's members """

		string_rep = u"(";

		# Get the members for this compound data type
		all_members = self.members.all();

		# A) Get the column index for each member
		member_indices = [member.column_idx for member in all_members];

		# B) Get the column index of each Datatype member, along with the Datatype member itself
		members_with_indices = [ (member_indices[i], all_members[i]) for i in range(len(all_members))];
		# Can we do this?
		# members_with_indices = [ (all_members[i].column_idx, all_members[i])
		#                          for i in range(len(all_members))];

		# Sort members using column index as a basis (operator.itemgetter(0))
		members_with_indices = sorted(	members_with_indices,
										key=operator.itemgetter(0));

		# Add sorted Datatype members to the string representation
		for i, colIdx_and_member in enumerate(members_with_indices):
			colIdx, member = colIdx_and_member;
			string_rep += unicode(member);

			# Add comma if not at the end of member list
			if i != len(members_with_indices) - 1:
				string_rep += ", ";

		string_rep += ")";

		if string_rep == "()":
			string_rep = "[empty CompoundDatatype]";

		return string_rep;

	# clean() is executed prior to save() to perform model validation
	def clean(self):
		"""Check if Datatype members have consecutive indices from 1 to n"""
		column_indices = [];

		# += is shorthand for extend() - concatenate a list with another list
		for member in self.members.all():
			column_indices += [member.column_idx];

		# Check if the sorted list is exactly a sequence from 1 to n
		if sorted(column_indices) != range(1, self.members.count()+1):
			raise ValidationError("Column indices are not consecutive starting from 1");


class Dataset(models.Model):
	"""
	Datasets uploaded by users, to be used as inputs for transformations.
	Related to :model:`copperfish.PipelineStep`
	Related to :model:`copperfish.CompoundDatatype`
	"""

	# Implicitly defined
	#   descendent_datasets (self/ManyToMany)

	# Activating admin panel creates a Users model
	user = models.ForeignKey(
			User,
			help_text="User that uploaded this dataset.");

	name = models.CharField(
			"Dataset name",
			max_length=128,
			help_text="Description of this dataset.");

	description = models.TextField("Dataset description");

	date_created = models.DateTimeField(
			"Date created",
			auto_now_add=True,
			help_text="Date of dataset upload.");


	# Pipeline step this Dataset come from (Null if Dataset was manually uploaded)
	pipeline_step = models.ForeignKey(
			"PipelineStep",
			related_name="data_produced",
			null=True,
			blank=True,
			help_text="The pipeline step this dataset was created by (If applicable)");

	# Output 'hole' within a pipeline the Dataset comes from
	pipeline_step_output = models.ForeignKey(
			"TransformationOutput",
			null=True,
			blank=True,
			help_text="The output 'hole' this dataset comes from (If applicable)");

	# Parent datasets this dataset is derived from
	parent_datasets = models.ManyToManyField(
			'self',
			related_name="descendent_datasets",
			null=True,
			blank=True);

	# Datasets are restricted by a compound data type
	compounddatatype = models.ForeignKey(
			CompoundDatatype,
			related_name="conforming_datasets");

	dataset_file = models.FileField(
			upload_to="Datasets",
			help_text="File path where datasets are stored");

	MD5_checksum = models.CharField(
			max_length=64,
			help_text="Used to check dataset file integrity");


	def __unicode__(self):
		"""Display the Dataset name, user, and date created."""

		return "{} (created by {} on {})".format(
				self.name,
				unicode(self.user),
				self.date_created);

	# Before completing a save(), generate the MD5 hash
	def clean(self):
		"""Compute MD5 checksum for the dataset and check that its source is correctly specified.
		
		If a file specified, populate the MD5 checksum.  Also check that the
		TransformationOutput that produced it comes from the specified PipelineStep.
		"""

		try:
			md5gen = hashlib.md5();
			md5gen.update(self.dataset_file.read());
			self.MD5_checksum = md5gen.hexdigest();

		except ValueError as e:
			print(e);
			print("No file found; setting MD5 checksum to the empty string.");
			self.MD5_checksum = "";

		# Either both pipeline_step and pipeline_step_output are specified or
		# neither is specified.  If they are both specified, check that they
		# are consistent with each other, i.e. that the output is actually one
		# belonging to the specified PipelineStep.
		if pipeline_step == None and pipeline_step_output != None:
			raise ValidationError(
				"No PipelineStep specified but an output from a PipelineStep is");
		
		elif pipeline_step != None and pipeline_step_output == None:
			raise ValidationError(
				"PipelineStep is specified but no output from it is");

		elif ((pipeline_step != None and pipeline_step_output != None) and
			  (pipeline_step.transformation != pipeline_step_output.transformation)):
			raise ValidationError(
				"Specified PipelineStep does not produce specified TransformationOutput");
 
class CodeResource(models.Model):
	"""
	A CodeResource is any file tracked by ShipYard.
	Related to :model:`copperfish.CodeResourceRevision`
	"""

	# Implicitly defined
	#   revisions (codeResourceRevision/ForeignKey)

	name = models.CharField(
			"Resource name",
			max_length=255,
			help_text="The name for this resource");

	filename = models.CharField(
			"Resource file name",
			max_length=255,
			help_text="The filename for this resource",
			blank=True);

	description = models.TextField("Resource description");

	def isValidFileName(self):

		# Code resources have no filenames if they are a meta-package of dependencies
		if self.filename == "":
			return True
	
		# File names cannot start with 1 or more spaces
		if re.search("^\s+", self.filename):
			return False

		# Names cannot end with 1 or more trailing spaces
		if re.search("\s+$", self.filename):
			return False

		# Names must be 1 or more of any from {alphanumeric, space, "-._()"}
		# This will prevent "../" as it contains a slash
		regex = "^[-_.() {}{}]+$".format(string.ascii_letters, string.digits)
		if re.search(regex, self.filename):
			pass
		else:
			return False

		return True

	def clean(self):
		"""
		CodeResource name must be valid.

		It must not contain a leading space character or "..",
		must not end in space, and be composed of letters,
		numbers, dash, underscore, paranthesis, and space.
		"""
		
		if self.isValidFileName():
			pass
		else:
			raise ValidationError("Invalid code resource filename");


	def __unicode__(self):
		return self.name;
	

class CodeResourceRevision(models.Model):
	"""
	A particular revision of a code resource.

	Related to :model:`copperfish.CodeResource`
	Related to :model:`copperfish.CodeResourceDependency`
	Related to :model:`copperfish.Method`
	"""

	# Implicitly defined
	#   descendents (self/ForeignKey)
	#   dependencies (CodeResourceDependency/ForeignKey)
	#   needed_by (CodeResourceDependency/ForeignKey)
	#   method_set (Method/ForeignKey) ???

	coderesource = models.ForeignKey(
			CodeResource,
			related_name="revisions");	
		
	revision_name = models.CharField(
			max_length=128,
			help_text="A name to differentiate revisions of a CodeResource");

	revision_DateTime = models.DateTimeField(
			auto_now_add=True,
			help_text="Date this resource revision was uploaded");

	revision_parent = models.ForeignKey(
			'self',
			related_name="descendants",
			null=True,
			blank=True);

	revision_desc = models.TextField(
			"Revision description",
			help_text="A description for this particular resource revision");

	content_file = models.FileField(
			"File contents",
			upload_to="CodeResources",
			null=True,
			blank=True,
			help_text="File contents of this code resource revision");

	MD5_checksum = models.CharField(
			max_length=64,
			blank=True,
			help_text="Used to validate file contents of this resource revision");

	def __unicode__(self):
		"""Represent a resource revision by it's CodeResource name and revision name"""
		
		# Admin can create CR without save() and allow CRRev to be created in memory
		# So, in MEMORY, a revision can temporarily have no corresponding CodeResource
		if not hasattr(self, "coderesource"):
			returnCodeResource = u"[no code resource set]"
		else:
			returnCodeResource = unicode(self.coderesource)

		if self.revision_name == "":
			returnRevisionName = u"[no revision name]"
		else:
			returnRevisionName = unicode(self.revision_name)

		string_rep = unicode(returnCodeResource + ' ' + returnRevisionName)
		return string_rep

	# This CRR includes it's own filename at the root
	def list_all_filepaths(self):
		"""Return all filepaths associated with this CodeResourceRevision.

		Filepaths are listed recursively following a root-first scheme,
		with the filepaths of the children listed in order.
		"""
		return self.list_all_filepaths_h(self.coderesource.filename)

	# Self is be a dependency CRR, base_name is it's file name, specified either
	# by the parent dependency layer, or in the case of a top-level CR, just CRR.name
	def list_all_filepaths_h(self, base_name):

		# Filepath includes the original file which has dependencies
		# If just a library of dependencies (IE, base_name=""), don't add base_path
		all_filepaths = []
		if base_name != "":
			all_filepaths = [unicode(base_name)]

		# For each dependency in this code resource revision
		for dep in self.dependencies.all():

			# Get all file paths of the CR of the child dependency relative to itself
			dep_fn = dep.depFileName;
			# If depFileName is blank, check and see if the corresponding CodeResource
			# had a filename (i.e. if this is a non-metapackage CRR and so there is
			# an associated file).
			if dep_fn == "":
				dep_fn = dep.requirement.coderesource.filename;
			
			inner_dep_paths = dep.requirement.list_all_filepaths_h(dep_fn)

			# Convert the paths from being relative to the child CRR to being
			# relative to the current parent CRR by appending pathing
			# information from the dependency layer
			for paths in inner_dep_paths:
				correctedPath = os.path.join(dep.depPath, paths)
				all_filepaths.append(unicode(correctedPath))

		return all_filepaths

	def has_circular_dependence(self):
		"""Detect any circular dependences defined in this CodeResourceRevision."""
		return self.has_circular_dependence_h([]);

	def has_circular_dependence_h(self, dependants):
		"""Helper for has_circular_dependence.

		dependants is an accumulator that tracks all of the all of the
		CRRs that have this one as a dependency.
		"""
		# Base case: self is dependant on itself, in which case, return true.
		if self in dependants:
			return True;
		
		# Recursive case: go to all dependencies and check them.
		check_dep = False;
		for dep in self.dependencies.all():
			if dep.requirement.has_circular_dependence_h(dependants + [self]):
				check_dep = True;

		return check_dep;

	def clean(self):
		"""Check coherence of this CodeResourceRevision.

		Tests for any circular dependency; does this CRR depend on
		itself at all?  Also, checks for conflicts in the
		dependencies.  Finally, if there is a file specified, fill in
		the MD5 checksum.
		"""
		# CodeResource can be a collection of dependencies and not contain
		# a file - in this case, MD5 has no meaning and shouldn't exist
		try:
			md5gen = hashlib.md5();
			md5gen.update(self.content_file.read());
			self.MD5_checksum = md5gen.hexdigest();

		except ValueError as e:
			self.MD5_checksum = "";

		# Check for a circular dependency.
		if self.has_circular_dependence():
			raise ValidationError("Self-referential dependency"); 

		# Check if dependencies conflict with each other
		listOfDependencyPaths = self.list_all_filepaths()
		if len(set(listOfDependencyPaths)) != len(listOfDependencyPaths):
			raise ValidationError("Conflicting dependencies");

		# If content file exists, it must have a file name
		if self.content_file and self.coderesource.filename == "":
			raise ValidationError("If content file exists, it must have a file name")

		# If no content file exists, it must not have a file name
		if not self.content_file and self.coderesource.filename != "":
			raise ValidationError("Cannot have a filename specified in the absence of a content file")

class CodeResourceDependency(models.Model):
	"""
	Dependencies of a CodeResourceRevision - themselves also CodeResources.
	Related to :model:`copperfish.CodeResourceRevision`
	"""

	coderesourcerevision = models.ForeignKey(CodeResourceRevision,
						 related_name="dependencies");

	# Dependency is a codeResourceRevision
	requirement = models.ForeignKey(CodeResourceRevision,
	                                related_name="needed_by");

	# Where to place it during runtime relative to the CodeResource that relies on this CodeResourceDependency
	# FIXME: specifies the subdirectory, and OPTIONALLY, the file name to adopt during execution
	depPath = models.CharField(
		"Dependency path",
		max_length=255,
		help_text="Where a code resource dependency must exist in the sandbox relative to it's parent");

	depFileName = models.CharField(
		"Dependency file name",
		max_length=255,
		help_text="The file name the dependency is given on the sandbox at execution",
		blank=True);

	def clean(self):
		"""
		depPath cannot reference ".."
		"""

		# Collapse down to a canonical path
		self.depPath = os.path.normpath(self.depPath)

		# Catch ".." on it's own
		if re.search("^\.\.$", self.depPath):
			raise ValidationError("depPath cannot reference ../");

		# Catch "../[whatever]"
		if re.search("^\.\./", self.depPath):
			raise ValidationError("depPath cannot reference ../");

		# This next case actually should never happen since we've collapsed down
		# to a canonical path.
		# Catch any occurrence of "/../" within a larger path (Ex: blah/../bar)
		if re.search("/\.\./", self.depPath):
			raise ValidationError("depPath cannot reference ../");

		# If the child CR is a meta-package (no filename), we cannot
		# have a depFileName as this makes no sense
		if self.requirement.coderesource.filename == "" and self.depFileName != "":
			raise ValidationError("Metapackage dependencies cannot have a depFileName");


	def __unicode__(self):
		"""Represent as [codeResourceRevision] requires [dependency] as [dependencyLocation]."""
		return u"{} requires {} as {}".format(
				unicode(self.coderesourcerevision),
				unicode(self.requirement),
				os.path.join(self.depPath, self.depFileName));

class TransformationFamily(models.Model):
	"""
	TransformationFamily is abstract and describes common
	parameters between MethodFamily and PipelineFamily.

	Extends :model:`copperfish.MethodFamily`
	Extends :model:`copperfish.PipelineFamily`
	"""

	name = models.CharField(
			"Transformation family name",
			max_length=128,
			help_text="The name given to a group of methods/pipelines");

	description = models.TextField(
			"Transformation family description",
			help_text="A description for this collection of methods/pipelines");

	def __unicode__(self):
		""" Describe transformation family by it's name """
		return self.name;

	class Meta:
		abstract = True;

class MethodFamily(TransformationFamily):
	"""
	MethodFamily groups revisions of Methods together.

	Inherits :model:`copperfish.TransformationFamily`
	Related to :model:`copperfish.Method`
	"""

	# Implicitly defined:
	#   members (Method/ForeignKey)

	pass

class PipelineFamily(TransformationFamily):
	"""
	PipelineFamily groups revisions of Pipelines together.

	Inherits :model:`copperfish.TransformationFamily`
	Related to :model:`copperfish.Pipeline`
	"""

	# Implicitly defined:
	#   members (Pipeline/ForeignKey)

	pass


class Transformation(models.Model):
	"""
	Abstract class that defines common parameters
	across Method revisions and Pipeline revisions.

	Extends :model:`copperfish.Method`
	Extends :model:`copperfish.Pipeline`
	Related to :model:`TransformationInput`
	Related to :model:`TransformationOutput`
	"""

	revision_name = models.CharField(
			"Transformation revision name",
			max_length=128,
			help_text="The name of this transformation revision");

	revision_DateTime = models.DateTimeField(
			"Revision creation date",
			auto_now_add = True);

	revision_desc = models.TextField(
			"Transformation revision description",
			help_text="Description of this transformation revision");

	# inputs/outputs associated with transformations via GenericForeignKey
	# And can be accessed from within Transformations via GenericRelation
	inputs = generic.GenericRelation("TransformationInput");
	outputs = generic.GenericRelation("TransformationOutput");

	class Meta:
		abstract = True;

	def check_input_indices(self):
		"""Check that input indices are numbered consecutively from 1"""

		# Append each input index (hole number) to a list
		input_nums = [];
		for curr_input in self.inputs.all():
			input_nums += [curr_input.dataset_idx];

		# Indices must be consecutively numbered from 1 to n
		if sorted(input_nums) != range(1, self.inputs.count()+1):
			raise ValidationError(
					"Inputs are not consecutively numbered starting from 1");
		
	def check_output_indices(self):
		"""Check that output indices are numbered consecutively from 1"""

		# Append each output index (hole number) to a list
		output_nums = [];
		for curr_output in self.outputs.all():
			output_nums += [curr_output.dataset_idx];

		# Indices must be consecutively numbered from 1 to n
		if sorted(output_nums) != range(1, self.outputs.count()+1):
			raise ValidationError(
					"Outputs are not consecutively numbered starting from 1");

	def clean(self):
		"""Validate transformation inputs and outputs."""

		self.check_input_indices();
		self.check_output_indices();
		# A transformation cannot have multiple definitions for column name or column index (CHECK TRANSFORMATION XPUT)

class Method(Transformation):
	"""
	Methods are atomic transformations.

	Inherits from :model:`copperfish.Transformation`
	Related to :model:`copperfish.CodeResource`
	Related to :model:`copperfish.MethodFamily`
	"""

	# Implicitly defined:
	#   descendants (self/ForeignKey)

	family = models.ForeignKey(
			MethodFamily,
			related_name="members");

	revision_parent = models.ForeignKey(
			"self",
			related_name = "descendants",
			null=True,
			blank=True);

	# Code resource revisions are executable if they link to Method
	driver = models.ForeignKey(CodeResourceRevision);

	def __unicode__(self):
		"""Represent a method by it's revision name and method family"""
		string_rep = u"Method {} {}".format("{}", self.revision_name);

		# MethodFamily may not be temporally saved in DB if created by admin
		if hasattr(self, "family"):
			string_rep = string_rep.format(unicode(self.family));
		else:
			string_rep = string_rep.format("[family unset]");

		return string_rep;

	def save(self, *args, **kwargs):
		"""
		Create or update a method revision.

		If a method revision being created is derived from a parental
		method revision, copy the parent input/outputs.
		"""

		# Inputs/outputs cannot be stored in the database unless this
		# method revision has itself first been saved to the database
		super(Method, self).save(*args, **kwargs);

		# If no parent revision exists, there are no input/outputs to copy
		if self.revision_parent == None:
			return None;

		# If parent revision exists, and inputs/outputs haven't been registered,
		# copy all inputs and outputs from the parent revision to this revision
		if self.inputs.count() + self.outputs.count() == 0:

			for parent_input in self.revision_parent.inputs.all():
				self.inputs.create(
						compounddatatype = parent_input.compounddatatype,
						dataset_name = parent_input.dataset_name,
						dataset_idx = parent_input.dataset_idx,
						min_row = parent_input.min_row,
						max_row = parent_input.max_row);

			for parent_output in self.revision_parent.outputs.all():
				self.outputs.create(
						compounddatatype = parent_output.compounddatatype,
						dataset_name = parent_output.dataset_name,
						dataset_idx = parent_output.dataset_idx,
						min_row = parent_output.min_row,
						max_row = parent_output.max_row);
				

class Pipeline(Transformation):
	"""
	A particular pipeline revision.

	Inherits from :model:`copperfish.Transformation`
	Related to :model:`copperfish.PipelineFamily`
	Related to :model:`copperfish.PipelineStep`
	Related to :model:`copperfish.PipelineOutputMapping`
	"""

	# Implicitly defined
	#   steps (PipelineStep/ForeignKey)
	#   descendants (self/ForeignKey)
	#   outmap (PipelineOutputMapping/ForeignKey)

	family = models.ForeignKey(
			PipelineFamily,
			related_name="members");	

	revision_parent = models.ForeignKey(
			"self",
			related_name = "descendants",
			null=True,
			blank=True);

	def __unicode__(self):
		"""Represent pipeline by revision name and pipeline family"""

		string_rep = u"Pipeline {} {}".format("{}", self.revision_name);

		# If family isn't set (if created from family admin page)
		if hasattr(self, "family"):
			string_rep = string_rep.format(unicode(self.family));
		else:
			string_rep = string_rep.format("[family unset]");

		return string_rep;
 
	# outmap describes the wiring leading to terminal pipeline outputs of a pipeline
	def clean(self):
		"""
		Validate pipeline revision inputs/outputs

		1) Pipeline STEPS must be consecutively starting from 1
		2) Pipeline INPUTS must be consecutively numbered from 1
		3) Inputs are available at a needed step and of the type expected
		4) Pipeline outputs are appropriately mapped from the pipeline's steps
		"""
		# Check that inputs are numbered consecutively from 1 (???)
		# We don't care about the outputs, but if they are set, check them (???)

		# Transformation.clean() - check for consecutive numbering of
		# input/outputs for this pipeline as a whole
		super(Pipeline, self).clean();

		# Internal pipeline STEP numbers must be consecutive from 1 to n
		all_steps = self.steps.all();
		step_nums = [];

		for step in all_steps:
			step_nums += [step.step_num];

		if sorted(step_nums) != range(1, len(all_steps)+1):
			raise ValidationError(
					"Steps are not consecutively numbered starting from 1");

		# Check that steps are coherent with each other
		#
		# Are inputs at each step...
		#	A) Available? (Produced by a previous step + not deleted, OR an absolute input)
		#	B) Of the correct CompoundDatatype? And, not have contrary min/max row constraints?

		# FIXME: Check that each input is fed with a single wire

		# For each Pipeline step
 		for step in all_steps:

			# Extract wiring parameters (PipelineStepInputWire) for each input
			for curr_wire in step.wires_in.all():
				# Output hole where source data originates.  This is a
				# TransformationInput if the step is 0 (i.e. we are
				# requesting a pipeline input) or a
				# TransformationOutput if the step is not 0 (i.e. we
				# are requesting the output from a previous pipeline
				# step).
				input_requested = curr_wire.provider_output;
				requested_from = curr_wire.step_providing_input;		# Pipeline step of wiring destination
				feed_to_input = curr_wire.transf_input;			# Input hole of wiring destination

				if requested_from == 0:
					# Get pipeline inputs of self (Pipeline; a
					# transformation); look for pipeline inputs that
					# match the desired wiring source output name.
					pipeline_inputs = self.inputs.all();
					if input_requested not in pipeline_inputs:
						raise ValidationError(
							"Pipeline does not have input \"{}\"".
							format(unicode(input_requested)));

				# If not from step 0, input derives from the output of a pipeline step
				else:

					# Look at the pipeline step referenced by the wiring parameter
					providing_step = all_steps[requested_from-1];

					# Do any outputs at this pipeline step/transformation have the name requested?
					source_step_outputs = providing_step.transformation.outputs.all();
					if input_requested not in source_step_outputs:
						raise ValidationError(
							"Transformation at step {} does not produce output \"{}\"".
							format(requested_from, unicode(input_requested)));

					# Was the data from this step's transformation output deleted?
					source_deleted_outputs = [x.dataset_to_delete
											  for x in providing_step.outputs_to_delete.all()];
					if input_requested in source_deleted_outputs:
						raise ValidationError(
								"Input \"{}\" from step {} to step {} is deleted prior to request".
								format(input_requested.dataset_name, requested_from,
									   step.step_num));

				# Check that the input and output connected by the
				# wire are compatible.  Don't check for
				# ValidationError because this was checked in the
				# clean() of PipelineStep.

				# FIXME: we're just going to enforce that feed_to_input
				# and input_requested have the same CompoundDatatype, rather
				# than making sure that their CompoundDatatypes match;
				# is this too restrictive?
				if input_requested.compounddatatype != feed_to_input.compounddatatype:
					raise ValidationError(
							"Data fed to input \"{}\" of step {} does not have the expected CompoundDatatype".
							format(feed_to_input.dataset_name, step.step_num));

				provided_min_row = 0;
				required_min_row = 0;

				# Source output row constraint
				if input_requested.min_row != None:
					provided_min_row = input_requested.min_row;

				# Destination input row constraint
				if feed_to_input.min_row != None:
					required_min_row = feed_to_input.min_row;

				# Check for contradictory min row constraints
				if (provided_min_row < required_min_row):
					raise ValidationError(
							"Data fed to input \"{}\" of step {} may have too few rows".
							format(feed_to_input.dataset_name, step.step_num));

				provided_max_row = float("inf");
				required_max_row = float("inf");

				if input_requested.max_row != None:
					provided_max_row = input_requested.max_row;

				if feed_to_input.max_row != None:
					required_max_row = feed_to_input.max_row;

				# Check for contradictory max row constraints
				if (provided_max_row > required_max_row):
					raise ValidationError(
							"Data fed to input \"{}\" of step {} may have too many rows".
							format(feed_to_input.dataset_name, step.step_num));

		# Check pipeline output wiring for coherence
		output_indices = [];

		for mapping in self.outmap.all():
			# This is a TransformationOutput.
			output_requested = mapping.provider_output;
			requested_from = mapping.step_providing_output;
			connect_to_output = mapping.output_name;
			output_indices += [mapping.output_idx];

			# Step must actually belong to this pipeline
			if requested_from > len(all_steps):
				raise ValidationError(
						"Output requested from a non-existent step");
			
			# Given it is valid, access that step for deeper inspection
			providing_step = all_steps[requested_from-1];

			# Try to find an output hole with a matching name
			if not providing_step.transformation.outputs.filter(pk=output_requested.pk).exists():
				raise ValidationError(
						"Transformation at step {} does not produce output \"{}\"".
						format(requested_from, output_requested));
			
			# Also determine if output was deleted by the step producing it
			if providing_step.outputs_to_delete.filter(dataset_to_delete=output_requested).exists():
				raise ValidationError(
						"Output \"{}\" from step {} is deleted prior to request".
						format(output_requested.dataset_name, requested_from));

		# Also check if pipeline outputs are numbered consecutively
		if sorted(output_indices) != range(1, self.outmap.count()+1):
			raise ValidationError(
					"Outputs are not consecutively numbered starting from 1");

	def create_outputs(self):
		"""	
		Delete existing pipeline outputs, and recreate them
		from output mappings (outmap).

		PRE: this should only be called after the pipeline has been verified by
		clean and the outmaps are known to be OK.
		"""
		# Be careful if customizing delete() of TransformationOutput
		self.outputs.all().delete();

		# outmap is derived from (PipelineOutputMapping/ForeignKey)
		# For each wiring, extract the wiring parameters
 		for mapping in self.outmap.all():
			output_requested = mapping.provider_output;
			connect_to_output = mapping.output_name;

			# Clone the referenced PipelineStep's TransformationOutput
			# to make the specified output for the pipeline.
			self.outputs.create(compounddatatype=output_requested.compounddatatype,
								dataset_name=connect_to_output,
								dataset_idx=mapping.output_idx,
								min_row=output_requested.min_row,
								max_row=output_requested.max_row);
 			

class PipelineStep(models.Model):
	"""
	A step within a Pipeline representing a single transformation
	operating on inputs that are either pre-loaded (Pipeline inputs)
	or derived from previous pipeline steps within the same pipeline.

	Related to :mode;:`copperfish.Dataset`
	Related to :model:`copperfish.Pipeline`
	Related to :model:`copperfish.Transformation`
	Related to :model:`copperfish.PipelineStepInput`
	Related to :model:`copperfish.PipelineStepDelete`
	"""

	# Implicitly defined
	#   wires_in (PipelineStepInputWire/ForeignKey)
	#   outputs_to_delete: from PipelineStepDelete

	pipeline = models.ForeignKey(
			Pipeline,
			related_name="steps");

	# Pipeline steps are associated with a transformation
	content_type = models.ForeignKey(
			ContentType,
			limit_choices_to = {"model__in": ("method", "pipeline")});

	object_id = models.PositiveIntegerField();
	transformation = generic.GenericForeignKey("content_type", "object_id");
	step_num = models.PositiveIntegerField(validators=[MinValueValidator(1)]);
	

	def __unicode__(self):
		""" Represent with the pipeline and step number """

		pipeline_name = "[no pipeline assigned]";	
		if hasattr(self, "pipeline"):
			pipeline_name = unicode(self.pipeline);
		return "{} step {}".format(pipeline_name, self.step_num);


	def recursive_pipeline_check(self, pipeline):
		"""Given a pipeline, check if this step contains it.

		PRECONDITION: the transformation at this step has been appropriately
		cleaned and does not contain any circularities.  If it does this
		function can be fragile!
		"""

		contains_pipeline = False;

		# Base case 1: the transformation is a method and can't possibly contain the pipeline.
		if type(self.transformation) == Method:
			contains_pipeline = False;

		# Base case 2: this step's transformation exactly equals the pipeline specified
		elif self.transformation == pipeline:
			contains_pipeline = True;

		# Recursive case: go through all of the target pipeline steps and check if
		# any substeps exactly equal the transformation: if it does, we have circular pipeline references
		else:
			transf_steps = self.transformation.steps.all();
			for step in transf_steps:
				step_contains_pipeline = step.recursive_pipeline_check(pipeline);
				if step_contains_pipeline:
					contains_pipeline = True;
		return contains_pipeline;

	def clean(self):
		"""
		Check coherence of this step of the pipeline.
		
		1) Do input wires come from prior steps?
		2) Do input wires map correctly to the transformation at this step?
		3) Do outputs marked for deletion come from this transformation?
		4) Does the transformation at this step contain the parent pipeline?
		
		A pipeline step that is clean is not necessarily complete - check
		complete_clean() for that.
		"""

		# Check recursively to see if this step's transformation contains
		# the specified pipeline at all.
		if self.recursive_pipeline_check(self.pipeline):
			raise ValidationError("Step {} contains the parent pipeline".
								  format(self.step_num));

			
		for curr_wire in self.wires_in.all():
			input_requested = curr_wire.provider_output;
			requested_from = curr_wire.step_providing_input;
			feed_to_input = curr_wire.transf_input;

			# Does this input come from a step prior to this one?
			if requested_from >= self.step_num:
				raise ValidationError(
						"Step {} requests input from a later step".
						format(self.step_num));

			# Does the transformation at this step have the specified input?
			try:
				self.transformation.inputs.get(pk=feed_to_input.pk);
			except TransformationInput.DoesNotExist as e:
				raise ValidationError ("Transformation at step {} does not have input \"{}\"".
						format(self.step_num, unicode(feed_to_input)));

		for curr_del in self.outputs_to_delete.all():
			to_del = curr_del.dataset_to_delete;

			# Check that to_del is one of the outputs of the current step's
			# Transformation.
			if self.transformation.outputs.\
				filter(pk=to_del.pk).count() == 0:
				raise ValidationError(
						"Transformation at step {} does not have output \"{}\"".
						format(self.step_num, unicode(to_del)));

	def complete_clean(self):
		"""Executed after the step's wiring has been fully defined, and
		to see if all inputs are quenched exactly once.

		1) Are all inputs for this step's transformation quenched?
		2) Are any inputs multiply-wired (with PipelineStepInputs)?
		"""
		self.clean()
			
		for transformationInput in self.transformation.inputs.all():
			# See if the input is specified exactly once.
			numMatches = self.wires_in.filter(transf_input=transformationInput).count()

			if numMatches == 0:
				raise ValidationError("Input \"{}\" to transformation at step {} is not wired".
									  format(transformationInput.dataset_name, self.step_num))

			elif numMatches > 1:
				raise ValidationError(
					"Input \"{}\" to transformation at step {} is wired more than once".
					format(transformationInput.dataset_name, self.step_num))

class PipelineStepInputWire(models.Model):
	"""
	Represents the "wires" feeding into the transformation of a
	particular pipeline step, specifically:

	A) Destination of wire (transf_input_name) - step implicitly defined
	B) Source of the wire (step_providing_input, provider_output_name)

	Related to :model:`copperfish.PipelineStep`
	"""
	
	# The step (Which has a transformation) where we define incoming wiring
	pipelinestep = models.ForeignKey(
			PipelineStep,
			related_name = "wires_in");
	
	# Input hole (TransformationInput) of the transformation
	# at this step to which the wire leads
	transf_input = models.ForeignKey(
			"TransformationInput",
			help_text="Wiring destination input hole");
	
	
	# (step_providing_input, provider_output) unambiguously defines
	# the source of the wire.  step_providing_input can't refer to a PipelineStep
	# as it might also refer to the pipeline's inputs (i.e. step 0).
 	step_providing_input = models.PositiveIntegerField("Step providing the input source",
													   help_text="Wiring source step");

	content_type = models.ForeignKey(
			ContentType,
			limit_choices_to = {"model__in": ("TransformationOutput",
											  "TransformationInput")});
	object_id = models.PositiveIntegerField();
	# Wiring source output hole.
	provider_output = generic.GenericForeignKey("content_type", "object_id");

	# step_providing_input must be PRIOR to this step (Time moves forward)

	# Coherence of data is already enforced by Pipeline

	def __unicode__(self):
		"""Represent PipelineStepInput with the pipeline step, and the wiring destination input name"""
		step_str = "[no pipeline step set]";
		if self.pipelinestep != None:
			step_str = unicode(self.pipelinestep);
		return "{}:{}".format(step_str, self.transf_input.dataset_name);	


class PipelineStepDelete(models.Model):
	"""
	PipelineStepDelete defines what output datasets can be immediately deleted.
	(Recall, each pipeline step involves a transformation that generates outputs)

	Related to :model:`copperfish.PipelineStep`
	"""
	pipelinestep = models.ForeignKey(
			PipelineStep,
			related_name="outputs_to_delete");

	# Again, coherence of data will be enforced at the Python level
	# (i.e. does this actually refer to a Dataset that will be produced
	# by the Transformation at this step)

	# TransformationOutput of the transformation at this step to delete
	dataset_to_delete = models.ForeignKey(
			"TransformationOutput",
			help_text="Annotation to delete data once generated");


class PipelineOutputMapping(models.Model):
	"""
	Defines which outputs of internal PipelineSteps are mapped to
	end-point Pipeline outputs once internal execution is complete.

	Thus, a definition of wires leading to external pipeline outputs.

	Related to :model:`copperfish.Pipeline`
	Related to :model:`copperfish.TransformationOutput` (Refactoring needed)
	"""

	pipeline = models.ForeignKey(
			Pipeline,
			related_name="outmap");

	output_name = models.CharField(
			"Output hole name",
			max_length=128,
			help_text="Pipeline output hole name");

	# We need to specify both the output name and the output index because
	# we are defining the outputs of the Pipeline indirectly through
	# this wiring information - name/index mapping is stored...?
	output_idx = models.PositiveIntegerField(
			"Output hole index",
			validators=[MinValueValidator(1)],
			help_text="Pipeline output hole index");

	# PRE: step_providing_output refers to an actual step of the pipeline
	# and provider_output_name actually refers to one of the outputs
	# at that step
	# The coherence of the data here will be enforced at the Python level

	# step_providing_output = models.ForeignKey(
	# 		PipelineStep,
	# 		help_text="Source step at which output comes from");
	step_providing_output = models.PositiveIntegerField(
			"Source pipeline step number",
			validators=[MinValueValidator(1)],
			help_text="Source step at which output comes from");

	provider_output = models.ForeignKey(
			"TransformationOutput",
			help_text="Source output hole");

	def __unicode__(self):
		""" Represent with the pipeline name, output index, and output name (???) """
		pipeline_name = "[no pipeline set]";
		if self.pipeline != None:
			pipeline_name = unicode(self.pipeline);

		return "{}:{} ({})".format(pipeline_name, self.output_idx,
								   self.output_name);


class TransformationXput(models.Model):
	"""
	Describes parameters common to all inputs and outputs
	of transformations - the "holes"

	Extends :model:`copperfish.TransformationInput`
	Extends :model:`copperfish.TransformationOutput`
	"""

	# TransformationXput describes the input/outputs of transformations
	# So this class can only be associated with method and pipeline
	content_type = models.ForeignKey(
			ContentType,
			limit_choices_to = {"model__in": ("method", "pipeline")});
	object_id = models.PositiveIntegerField();
	transformation = generic.GenericForeignKey("content_type", "object_id");

	# The expected compounddatatype of the input/output
	compounddatatype = models.ForeignKey(CompoundDatatype);

	# The name of the "input/output" hole
	dataset_name = models.CharField(
			"Input/output name",
			max_length=128,
			help_text="Name for input/output as an alternative to index");

	# Input/output index on the transformation

	####### NOTE: ONLY METHODS NEED INDICES, NOT TRANSFORMATIONS....!!
	# If we differentiate between methods/pipelines... dataset_idx would only
	# belong to methods

	dataset_idx = models.PositiveIntegerField(
			"Input/output index",
			validators=[MinValueValidator(1)],
			help_text="Index defining the relative order of this input/output");
	
	# Nullable fields indicating that this dataset has
	# restrictions on how many rows it can have
	min_row = models.PositiveIntegerField(
		"Minimum row",
		help_text="Minimum number of rows this input/output returns",
		null=True,
		blank=True);

	max_row = models.PositiveIntegerField(
		"Maximum row",
		help_text="Maximum number of rows this input/output returns",
		null=True,
		blank=True);

	class Meta:
		abstract = True;

		# A transformation cannot have multiple definitions for column name or column index
		unique_together = (("content_type", "object_id", "dataset_name"),
						   ("content_type", "object_id", "dataset_idx"));

	def __unicode__(self):
		return u"[{}]:{} {} {}".format(unicode(self.transformation),
									   self.dataset_idx,
									   unicode(self.compounddatatype),
									   self.dataset_name);

class TransformationInput(TransformationXput):
	"""
	Inherits from :model:`copperfish.TransformationXput`
	"""
	pass

class TransformationOutput(TransformationXput):
	"""
	Inherits from :model:`copperfish.TransformationXput`
	"""
	pass
