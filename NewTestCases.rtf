{\rtf1\ansi\ansicpg1252\cocoartf1138\cocoasubrtf510
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;\red0\green61\blue204;\red206\green59\blue0;}
\margl1440\margr1440\vieww26180\viewh9640\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural

\f0\b\fs24 \cf0 Write scripts
\b0 \
\cf2 1A) Takes raw input, outputs CSV input\
script_4_raw_in_CSV_out.py:	Inputs raw (a,b,c) and outputs CSV (a^2, b^2, c^2)\
1B) Takes CSV input, outputs raw\
script_5_CSV_in_raw_out.py:	Inputs CSV (a,b,c) and outputs RAW (a^2,b^2,c^2)\
1C) Takes raw input, outputs raw (Can be dumb)\
script_6_raw_in_raw_out.py:	Inputs raw (a,b,c) and outputs raw (a^2,b^2,c^2)\cf0 \
1D) One that "mixes and matches" (??)\
\

\b Transformation (Raw inputs incorporated)
\b0 \
\cf2  - Indices (uniqueness and consecutive-ness), naming uniqueness (check_(in|out)put_(names|indices)) - DONE!\cf0 \
\cf2  - Check clean for propagation - DONE!\cf0 \
 - Focus on Method, do maybe 1-2 cases for Pipeline\
\

\b \cf2 Method
\b0 \
 - Save: check that raw_xputs are copied, no copying is done if *any* (raw)xputs already defined - DONE!\cf0 \
\

\b PipelineStepRawInputCable
\b0 \
\cf2  - pipeline_raw_input must come from this pipeline's TransformationRawInputs (Raw inputs only connect from step 0)\cf0 \
\cf3  - Destination TransformationRawInput must belong to a PS Transformation in this pipeline\cf0 \
transf_raw_input = destination raw input hole\
\

\b PipelineRawOutputCable
\b0 \
 - Check Pipeline.clean for indexing and naming\
\cf2  - Step referenced must be valid (step number <= total number of steps)\cf0 \
 - Must reference a TransformationRawOutput from the specified PS\
\cf2  - Referenced TransformationRawOutput must not be deleted\cf0 \
\

\b PipelineStepRawDelete
\b0 \
 - Has a clean method\
 - 1 or 2 checks on PS.clean (just propagation of errors)\
 - maybe 1 or 2 checks on Pipeline.clean (but this is just propagation of errors)\
\

\b Datasets
\b0 \
At some point we're going to need to start validating Datasets, which gets us into validating Datatypes and executing validation scripts.\
We'll put this off until we start working on execute.\
\

\b \cf2 AbstractDataset
\b0 \
 - Confirm MD5 checksum\
\

\b Dataset
\b0 \
 - If AbstractDataset.pipeline_step is set, Dataset.pipeline_step_output must be valid:\
   - Is specified, not None\
   - Belongs to the specified PS\
 - Check that if pipeline_step_output is set, then so is pipeline_step\
 - Check its ability to test that Dataset CDT matches the pipeline_step's CDT\
 - Test its ability to look at the header of a CSV file for coherence\
 - Validate num_rows\
\

\b RawDataset
\b0 \
 - check that if pipeline_step is set, then pipeline_step_raw_output is valid:\
   - is specified, not None\
   - belongs to the specified PS\
 - check that if pipeline_step_output is set, then so is pipeline_step\cf0 \
\

\b ParentDataset
\b0 \
 - Test with child being a Dataset and a RawDataset (??)\
 - Test that parent_input belongs to the Transformation of the PS producing the child (Raw)Dataset\
 - Test that parent fits correctly into parent_input (??)\
   - without wiring\
   - with wiring\
\

\i Notes on ParentDataset
\i0 \
dataset - the child which can be raw or non-raw.\
parent - a non-raw parent dataset that went into producing this child.\
parent_input - the transformation input that the parent was plugged into.\
\

\b RawParentDataset
\b0 \
 - Test that parent_raw_input is a pipeline input of the generating pipeline \
(because raw parents can only ever come from the generating pipeline's inputs)\
\
Check on the issue of whether we need to close and reopen the FieldFile whenever we access.}