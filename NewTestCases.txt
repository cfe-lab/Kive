Things to check:

make scripts that take raw input and convert to CSV, take CSV and convert to raw (just use something already there), take raw input and produce raw output (can be really dumb), and one that mixes and matches.

Transformation:
 - indices (uniqueness and consecutive-ness), naming uniqueness (check_(in|out)put_(names|indices))
 - also check clean for propagation
 _ do this for Method, maybe 1-2 cases for Pipeline

Method:
 - save(): check that raw_xputs are copied, no copying is done if *any* (raw)xputs are defined

PipelineStepRawInputCable
 - check that source TransformationRawInput is a Pipeline input
 - check that the destination TransformationRawInput belongs to the PS's Transformation
 - will propagate upwards to PS.clean (complete_clean), Pipeline.clean (complete_clean)

PipelineRawOutputCable
 - incurs a change in Pipeline.clean to check indexing and naming
 - step referenced must be valid (i.e. step number <= total number of steps)
 - references a TransformationRawOutput from the specified PS
 - the referenced TRO is not deleted

PipelineStepRawDelete
 - has a clean method
 - 1 or 2 checks on PS.clean (just propagation of errors)
 - maybe 1 or 2 checks on Pipeline.clean (but this is just propagation of errors)

Put all of the above tests in a new "raw xput" test class

----

Dataset stuff:

Note that at some point we're going to need to start validating Datasets, which gets us into the whole thing of validating Datatypes and executing validation scripts.  We'll put this off until we start working on execute; i.e. when we start actually running scripts.  In fact this is part of execute; it's something that will be called between steps of pipelines.

Check on the issue of whether we need to close and reopen the FieldFile whenever we access.

AbstractDataset:
 - check for proper MD5 setting

Dataset:
 - check that if pipeline_step is set, then pipeline_step_output is valid:
   - is specified, not None
   - belongs to the specified PS
 - check that if pipeline_step_output is set, then so is pipeline_step
 - check its ability to test that Dataset CDT matches the pipeline_step's CDT
 - test its ability to look at the header of a CSV file for coherence
 - check num_rows

RawDataset:
 - check that if pipeline_step is set, then pipeline_step_output is valid:
   - is specified, not None
   - belongs to the specified PS
 - check that if pipeline_step_output is set, then so is pipeline_step

ParentDataset:
Things specified:
 - dataset (the child)
 - parent (a Dataset that went into producing this child)
 - parent_input (the TI that parent was plugged into)
We check:
 - test with child being a Dataset and a RawDataset
 - test that parent_input belongs to the Transformation of the PS producing the child (Raw)Dataset
 - test that parent fits correctly into parent_input:
   - without wiring
   - with wiring

RawParentDataset:
 - test that parent_raw_input is a pipeline input of the generating pipeline (because raw parents can only ever come from the generating pipeline's inputs)